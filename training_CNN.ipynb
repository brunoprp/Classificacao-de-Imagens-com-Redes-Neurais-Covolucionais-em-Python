{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import image_processing #import the image processing script\n",
    "\n",
    "dire_train = 'data/train/' #trainig diretory\n",
    "dire_test = 'data/test/' #test diretory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the test and training images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5101/5101 [00:53<00:00, 82.74it/s] \n",
      "100%|██████████| 625/625 [00:05<00:00, 114.12it/s]\n"
     ]
    }
   ],
   "source": [
    "sizeImg = 200 #image dimension\n",
    "images = image_processing.ImageProcessing() #Instantiating an object from class (ImageProcessing)\n",
    "\n",
    "x_train, y_train = images.loadImages(dire_train,sizeImg) #Trainig image processing \n",
    "x_test, y_test = images.loadImages(dire_test,sizeImg) #Test imge processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model of convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Importing the Keras library for model building\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setting Network Hyperparameters\"\"\"\n",
    "EPOCHS = 20 #Epocha number\n",
    "INIT_LR = 1e-3 #Learning rate\n",
    "BS = 40 # batch size, amount of images that will pass through the network in each season\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / 100) #optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0919 15:02:54.266713 139754306234176 deprecation_wrapper.py:119] From /home/bruno/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0919 15:02:54.272680 139754306234176 deprecation_wrapper.py:119] From /home/bruno/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0919 15:02:54.276598 139754306234176 deprecation_wrapper.py:119] From /home/bruno/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0919 15:02:54.373131 139754306234176 deprecation_wrapper.py:119] From /home/bruno/anaconda3/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0919 15:02:54.381150 139754306234176 deprecation_wrapper.py:119] From /home/bruno/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 196, 196, 32)      18464     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 194, 194, 16)      4624      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 602176)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                9634832   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 9,658,714\n",
      "Trainable params: 9,658,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # Sequential model keras\n",
    "#add model layers\n",
    "\"\"\"Convolutional layers\"\"\"\n",
    "model.add(Conv2D(64, kernel_size = 3, activation = 'relu', input_shape=(sizeImg,sizeImg,1))) #\n",
    "model.add(Conv2D(32, kernel_size = 3, activation = 'relu'))\n",
    "model.add(Conv2D(16, kernel_size = 3, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "\"\"\"Dense layers\"\"\"\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))# the last layer must have the same number of classes\n",
    "model.compile(optimizer = opt, loss='categorical_crossentropy',metrics=['accuracy']) #Compiling the model by defining the optimizer the loss function and the evaluation metric\n",
    "model.summary()#Print CNN architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0919 15:03:09.056821 139754306234176 deprecation.py:323] From /home/bruno/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0919 15:03:09.135034 139754306234176 deprecation_wrapper.py:119] From /home/bruno/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "127/127 [==============================] - 37s 291ms/step - loss: 0.4589 - acc: 0.7909 - val_loss: 0.3222 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.86705, saving model to model.h5\n",
      "Epoch 2/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.3221 - acc: 0.8669 - val_loss: 0.5728 - val_acc: 0.7245\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.86705\n",
      "Epoch 3/20\n",
      "127/127 [==============================] - 29s 230ms/step - loss: 0.2916 - acc: 0.8738 - val_loss: 0.3027 - val_acc: 0.8796\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.86705 to 0.87963, saving model to model.h5\n",
      "Epoch 4/20\n",
      "127/127 [==============================] - 29s 230ms/step - loss: 0.2639 - acc: 0.8947 - val_loss: 0.2651 - val_acc: 0.8983\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.87963 to 0.89832, saving model to model.h5\n",
      "Epoch 5/20\n",
      "127/127 [==============================] - 29s 230ms/step - loss: 0.2543 - acc: 0.8965 - val_loss: 0.2566 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89832\n",
      "Epoch 6/20\n",
      "127/127 [==============================] - 29s 230ms/step - loss: 0.2614 - acc: 0.8923 - val_loss: 0.2821 - val_acc: 0.8829\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89832\n",
      "Epoch 7/20\n",
      "127/127 [==============================] - 29s 232ms/step - loss: 0.2600 - acc: 0.8935 - val_loss: 0.2588 - val_acc: 0.8962\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89832\n",
      "Epoch 8/20\n",
      "127/127 [==============================] - 29s 229ms/step - loss: 0.2334 - acc: 0.9022 - val_loss: 0.2658 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89832\n",
      "Epoch 9/20\n",
      "127/127 [==============================] - 29s 231ms/step - loss: 0.2381 - acc: 0.9041 - val_loss: 0.2346 - val_acc: 0.9053\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.89832 to 0.90531, saving model to model.h5\n",
      "Epoch 10/20\n",
      "127/127 [==============================] - 29s 231ms/step - loss: 0.2081 - acc: 0.9163 - val_loss: 0.2261 - val_acc: 0.9093\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.90531 to 0.90933, saving model to model.h5\n",
      "Epoch 11/20\n",
      "127/127 [==============================] - 29s 229ms/step - loss: 0.2480 - acc: 0.9045 - val_loss: 0.2928 - val_acc: 0.8805\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.90933\n",
      "Epoch 12/20\n",
      "127/127 [==============================] - 29s 230ms/step - loss: 0.2167 - acc: 0.9171 - val_loss: 0.2688 - val_acc: 0.8948\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.90933\n",
      "Epoch 13/20\n",
      "127/127 [==============================] - 29s 230ms/step - loss: 0.2074 - acc: 0.9199 - val_loss: 0.2020 - val_acc: 0.9214\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.90933 to 0.92138, saving model to model.h5\n",
      "Epoch 14/20\n",
      "127/127 [==============================] - 29s 231ms/step - loss: 0.2103 - acc: 0.9219 - val_loss: 0.3137 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.92138\n",
      "Epoch 15/20\n",
      "127/127 [==============================] - 29s 231ms/step - loss: 0.2107 - acc: 0.9134 - val_loss: 0.2235 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.92138 to 0.92226, saving model to model.h5\n",
      "Epoch 16/20\n",
      "127/127 [==============================] - 29s 232ms/step - loss: 0.2000 - acc: 0.9248 - val_loss: 0.3628 - val_acc: 0.8363\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.92226\n",
      "Epoch 17/20\n",
      "127/127 [==============================] - 30s 233ms/step - loss: 0.2020 - acc: 0.9205 - val_loss: 0.2972 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.92226\n",
      "Epoch 18/20\n",
      "127/127 [==============================] - 29s 231ms/step - loss: 0.1855 - acc: 0.9295 - val_loss: 0.2483 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.92226\n",
      "Epoch 19/20\n",
      "127/127 [==============================] - 29s 231ms/step - loss: 0.1825 - acc: 0.9309 - val_loss: 0.1823 - val_acc: 0.9289\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.92226 to 0.92890, saving model to model.h5\n",
      "Epoch 20/20\n",
      "127/127 [==============================] - 29s 231ms/step - loss: 0.1815 - acc: 0.9323 - val_loss: 0.1947 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.92890\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Save model treined\"\"\"\n",
    "filepath='model.h5'#name model save\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')#salve best model\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\"\"\"here a keras technique is used to improve training accuracy, the images are molded for the network to learn better\"\"\"\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "\"\"\"CNN trained by passing training and test data jutamnete with hyperparameters\"\"\"\n",
    "history = model.fit_generator(\n",
    "    aug.flow(x_train, y_train, batch_size=BS),\n",
    "    validation_data=(x_test, y_test),\n",
    "    steps_per_epoch=len(x_train) // BS,\n",
    "    epochs=EPOCHS, verbose=1, callbacks = callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
