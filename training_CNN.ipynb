{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_processing #import the image processing script\n",
    "\n",
    "dire_train = 'data/train/' #trainig diretory\n",
    "dire_test = 'data/test/' #test diretory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the test and training images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5101/5101 [00:54<00:00, 93.87it/s] \n",
      "100%|██████████| 625/625 [00:05<00:00, 112.08it/s]\n"
     ]
    }
   ],
   "source": [
    "sizeImg = 200 #image dimension\n",
    "images = image_processing.ImageProcessing() #Instantiating an object from class (ImageProcessing)\n",
    "\n",
    "x_train, y_train = images.loadImages(dire_train,sizeImg) #Trainig image processing \n",
    "x_test, y_test = images.loadImages(dire_test,sizeImg) #Test imge processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model of convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Importing the Keras library for model building\"\"\"\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Setting Network Hyperparameters\"\"\"\n",
    "EPOCHS = 20 #Epocha number\n",
    "INIT_LR = 1e-3 #Learning rate\n",
    "BS = 40 # batch size, amount of images that will pass through the network in each season\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / 100) #optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 198, 198, 64)      640       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 196, 196, 32)      18464     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 194, 194, 16)      4624      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 602176)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                9634832   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 18        \n",
      "=================================================================\n",
      "Total params: 9,658,714\n",
      "Trainable params: 9,658,714\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() # Sequential model keras\n",
    "#add model layers\n",
    "\"\"\"Convolutional layers\"\"\"\n",
    "model.add(Conv2D(64, kernel_size = 3, activation = 'relu', input_shape=(sizeImg,sizeImg,1))) #\n",
    "model.add(Conv2D(32, kernel_size = 3, activation = 'relu'))\n",
    "model.add(Conv2D(16, kernel_size = 3, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "\"\"\"Dense layers\"\"\"\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))# the last layer must have the same number of classes\n",
    "model.compile(optimizer = opt, loss='categorical_crossentropy',metrics=['accuracy']) #Compiling the model by defining the optimizer the loss function and the evaluation metric\n",
    "model.summary()#Print CNN architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "127/127 [==============================] - 31s 242ms/step - loss: 0.5845 - acc: 0.7459 - val_loss: 0.3674 - val_acc: 0.8288\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.82879, saving model to model.h5\n",
      "Epoch 2/20\n",
      "127/127 [==============================] - 30s 233ms/step - loss: 0.3450 - acc: 0.8350 - val_loss: 0.3752 - val_acc: 0.8262\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.82879\n",
      "Epoch 3/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.3192 - acc: 0.8783 - val_loss: 0.3135 - val_acc: 0.9064\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.82879 to 0.90636, saving model to model.h5\n",
      "Epoch 4/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.3024 - acc: 0.8854 - val_loss: 0.2979 - val_acc: 0.8981\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90636\n",
      "Epoch 5/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.2849 - acc: 0.8898 - val_loss: 0.2945 - val_acc: 0.9050\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90636\n",
      "Epoch 6/20\n",
      "127/127 [==============================] - 30s 237ms/step - loss: 0.2806 - acc: 0.8927 - val_loss: 0.2677 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.90636 to 0.91230, saving model to model.h5\n",
      "Epoch 7/20\n",
      "127/127 [==============================] - 30s 234ms/step - loss: 0.2553 - acc: 0.9049 - val_loss: 0.2835 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.91230\n",
      "Epoch 8/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.2696 - acc: 0.8951 - val_loss: 0.2902 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.91230\n",
      "Epoch 9/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.2561 - acc: 0.9030 - val_loss: 0.2467 - val_acc: 0.9074\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.91230\n",
      "Epoch 10/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.2498 - acc: 0.9035 - val_loss: 0.2192 - val_acc: 0.9312\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.91230 to 0.93117, saving model to model.h5\n",
      "Epoch 11/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.2325 - acc: 0.9189 - val_loss: 0.1954 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.93117 to 0.93990, saving model to model.h5\n",
      "Epoch 12/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.2363 - acc: 0.9136 - val_loss: 0.1986 - val_acc: 0.9382\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.93990\n",
      "Epoch 13/20\n",
      "127/127 [==============================] - 30s 236ms/step - loss: 0.2223 - acc: 0.9154 - val_loss: 0.2497 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.93990\n",
      "Epoch 14/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.2170 - acc: 0.9181 - val_loss: 0.2250 - val_acc: 0.9189\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.93990\n",
      "Epoch 15/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.2345 - acc: 0.9150 - val_loss: 0.2696 - val_acc: 0.8878\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.93990\n",
      "Epoch 16/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.2103 - acc: 0.9248 - val_loss: 0.2496 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.93990\n",
      "Epoch 17/20\n",
      "127/127 [==============================] - 30s 235ms/step - loss: 0.1949 - acc: 0.9319 - val_loss: 0.1760 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.93990 to 0.94567, saving model to model.h5\n",
      "Epoch 18/20\n",
      "127/127 [==============================] - 30s 236ms/step - loss: 0.2005 - acc: 0.9264 - val_loss: 0.1913 - val_acc: 0.9352\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.94567\n",
      "Epoch 19/20\n",
      "127/127 [==============================] - 30s 232ms/step - loss: 0.1917 - acc: 0.9276 - val_loss: 0.1947 - val_acc: 0.9294\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.94567\n",
      "Epoch 20/20\n",
      "127/127 [==============================] - 30s 233ms/step - loss: 0.1975 - acc: 0.9240 - val_loss: 0.1865 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.94567\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Save model treined\"\"\"\n",
    "filepath='model.h5'#name model save\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')#salve best model\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\"\"\"here a keras technique is used to improve training accuracy, the images are molded for the network to learn better\"\"\"\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "\"\"\"CNN trained by passing training and test data jutamnete with hyperparameters\"\"\"\n",
    "history = model.fit_generator(\n",
    "    aug.flow(x_train, y_train, batch_size=BS),\n",
    "    validation_data=(x_test, y_test),\n",
    "    steps_per_epoch=len(x_train) // BS,\n",
    "    epochs=EPOCHS, verbose=1, callbacks = callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
